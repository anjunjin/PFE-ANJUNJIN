{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tweeter & Fake News",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anjunjin/PFE-ING3-IA/blob/branch1/Tweeter_%26_Fake_News.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgIMZx7EsiMn"
      },
      "source": [
        "# Tweeter & Fake news\n",
        "Notebook jupyter du projet tweeter et fake news par Arnaud Valette & Paul Planchon\n",
        "\n",
        "run the first cell once to be sure all the librairies are installed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "tags": [],
        "id": "GWVJ5SqjpjHT"
      },
      "source": [
        "!pip install tweepy pandas numpy matplotlib python-dotenv tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQ2HXk2oshYb"
      },
      "source": [
        "import tweepy\n",
        "import pickle\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from dotenv import dotenv_values\n",
        "import requests\n",
        "from IPython.display import JSON"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VY419EhpjHY"
      },
      "source": [
        "### env vars\n",
        "in a folder `../creds` put an .env file with\n",
        "```\n",
        "API_KEY=\"\"\n",
        "API_SECRET=\"\"\n",
        "API_TOKEN=\"\"\n",
        "```\n",
        "which are the creds from twitter dev portal [twitter portal](https://developer.twitter.com/en/portal/projects/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bylFSz2jtIVz",
        "outputId": "4533e455-3a04-463e-eab3-35f14f25383e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "DATA_PATH = \"/content/drive/My Drive/PFE/\""
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2JVsJRapjHZ"
      },
      "source": [
        "# env_var = dotenv_values(\"../.env\")\n",
        "# API_KEY    = env_var[\"API_KEY\"]\n",
        "# API_SECRET = env_var[\"API_SECRET\"]\n",
        "# API_TOKEN  = env_var[\"API_TOKEN\"]\n",
        "\n",
        "API_TOKEN = pd.read_csv(DATA_PATH+\"Clés.csv\", encoding='utf-8', sep=',')['Bearer Token'][0]\n",
        "API_KEY = pd.read_csv(DATA_PATH+\"Clés.csv\", encoding='utf-8', sep=',')['API Key'][0]\n",
        "API_SECRET = pd.read_csv(DATA_PATH+\"Clés.csv\", encoding='utf-8', sep=',')['API Key Secret'][0]"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34GIIGrWpjHZ"
      },
      "source": [
        "auth = tweepy.AppAuthHandler(API_KEY, API_SECRET)\n",
        "api = tweepy.API(auth, wait_on_rate_limit=True)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuz1dZFTpjHa"
      },
      "source": [
        "## Monde website data\n",
        "getting the JSON data from [le monde](https://www.lemonde.fr/webservice/decodex/updates) decodex updates feed\n",
        "\n",
        "### categories\n",
        " - 1: Site parodique\n",
        " - 2: Fake news\n",
        " - 3: Faire attention\n",
        " - 4: OK mais il ne faut pas hésiter a croiser"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbxKvfdwpjHa"
      },
      "source": [
        "data = requests.get(\"https://www.lemonde.fr/webservice/decodex/updates\").json()"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7v6KApgkpjHb"
      },
      "source": [
        "try:\n",
        "    decodex_site = pd.read_csv(\"./monde_site.csv\", index_col=0)\n",
        "    with open('monde_urls.pickle', 'rb') as handle:\n",
        "        site_index_to_url = pickle.load(handle)\n",
        "except Exception:\n",
        "    decodex_site = pd.DataFrame(requests.get(\"https://www.lemonde.fr/webservice/decodex/updates\").json()[\"sites\"]).T.drop(3, 1).rename(columns={0: \"categorie\", 1: \"description\", 2: \"site\"})\n",
        "    decodex_url = requests.get(\"https://www.lemonde.fr/webservice/decodex/updates\").json()[\"urls\"] # urls of website, including sometimes twitter data\n",
        "\n",
        "    # convert the url to index dict to an index to url dict\n",
        "    site_index_to_url = {}\n",
        "    for x, y in decodex_url.items():\n",
        "        try:\n",
        "            if site_index_to_url[y]:\n",
        "                site_index_to_url[y].append(x)\n",
        "        except Exception as e:\n",
        "            site_index_to_url[y] = [x]\n",
        "\n",
        "    # we save data to disk\n",
        "    decodex_site.to_csv(\"monde_site.csv\")\n",
        "    with open('monde_urls.pickle', 'wb') as handle:\n",
        "        pickle.dump(site_index_to_url, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VVWXp7WFxdJ"
      },
      "source": [
        "#Si vous utilisez cette ligne, pensez à bien fermer la fenêtre de résultat pour des raison de sécurité\n",
        "# decodex_site"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3D9-GgBpjHd"
      },
      "source": [
        "# get alls twitter link from the urls of decodex\n",
        "# fake_news_index = list(decodex_site[decodex_site[\"categorie\"] == 2].index) #Ne prend que les sites de catégorie \"Fake News\"\n",
        "fake_news_index = list(decodex_site.index) #Prend tous les sites, peut importe la catégorie\n",
        "fake_news_twitter = {}\n",
        "\n",
        "for i in fake_news_index:\n",
        "    try:\n",
        "        for url in site_index_to_url[int(i)]:\n",
        "            if \"twitter.com/\" in url:\n",
        "                if \"?lang=fr\" in url:\n",
        "                    size = len(url)\n",
        "                    fake_news_twitter[i] = url[12:size - 8].strip('@')\n",
        "                else:\n",
        "                    fake_news_twitter[i] = url[12:].strip('@')\n",
        "    except Exception as e:\n",
        "        pass"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pODa0aZPpjHd"
      },
      "source": [
        "#Si vous utilisez cette ligne, pensez à bien fermer la fenêtre de résultat pour des raison de sécurité\n",
        "# fake_news_twitter"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmKk6627pjHe"
      },
      "source": [
        "    class TwitterUser():\n",
        "        _screen_name = \"\"\n",
        "        _id = \"\"\n",
        "        _user_data = None\n",
        "        followers = []\n",
        "        following = []\n",
        "        tweet = []\n",
        "        like = []\n",
        "        request_count = 0\n",
        "\n",
        "        def __init__(self, sname = \"\", _json = {}):\n",
        "            if (sname != \"\"):\n",
        "                self._screen_name = sname\n",
        "                self.get_info()\n",
        "            if (_json != {}):\n",
        "                self._json = _json\n",
        "\n",
        "        def get_info(self):\n",
        "            self._user_data = api.get_user(screen_name=self._screen_name)\n",
        "\n",
        "        def get_all_data(self):\n",
        "            self.get_tweets()\n",
        "            # self.get_followers()\n",
        "            # self.get_following()\n",
        "            # self.get_like()\n",
        "\n",
        "        def set_name(self, name):\n",
        "            self._screen_name = name\n",
        "\n",
        "        def set_id(self, _id):\n",
        "            self._id = _id\n",
        "\n",
        "        def get_followers(self):\n",
        "            with tqdm(total=self._user_data.followers_count, desc=\"get_followers for \" + self._user_data.screen_name) as pbar:\n",
        "                for page in tweepy.Cursor(api.followers, screen_name=self._screen_name, count=200).pages():\n",
        "                    self.followers.extend(page)\n",
        "                    pbar.update(len(page))\n",
        "\n",
        "\n",
        "        def get_following(self):\n",
        "            with tqdm(total=self._user_data.friends_count, desc=\"get_following for \" + self._user_data.screen_name) as pbar:\n",
        "                for page in tweepy.Cursor(api.friends, screen_name=self._screen_name, count=200).pages():\n",
        "                    self.following.extend(page)\n",
        "                    pbar.update(len(page))\n",
        "\n",
        "        # on ne peut prendre que les 3000 derniers\n",
        "        def get_tweets(self):\n",
        "            if self._user_data.protected:\n",
        "                print(\"can't get tweets from \" + self._user_data.screen_name + \", the account is protected\")\n",
        "            else:\n",
        "                with tqdm(total=3000, desc=\"get_tweets for \" + self._user_data.screen_name) as pbar:\n",
        "                    for page in tweepy.Cursor(api.user_timeline, screen_name=self._screen_name, count=200).pages():\n",
        "                        self.tweet.extend(page)\n",
        "                        pbar.update(len(page))\n",
        "\n",
        "        # on ne peut prendre que les 3000 derniers\n",
        "        def get_like(self):\n",
        "            if self._user_data.protected:\n",
        "                print(\"can get like from \" + self._user_data.screen_name + \", the account is protected\")\n",
        "            else:\n",
        "                with tqdm(total=3000, desc=\"get_likes for \" + self._user_data.screen_name) as pbar:\n",
        "                    for page in tweepy.Cursor(api.favorites, screen_name=self._screen_name, count=200).pages():\n",
        "                        self.like.extend(page)\n",
        "                        pbar.update(len(page))\n"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nb1YRijpjHe"
      },
      "source": [
        "# test = TwitterUser(sname=\"EuroScoop_FR\")\n",
        "# test.get_all_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOXn1OFD5g3y"
      },
      "source": [
        "# test.tweet[0].text"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "k9UZ8VfEIlXP",
        "outputId": "006c3934-4730-4ace-d7fb-d57a4238295c"
      },
      "source": [
        "import pickle\n",
        "\n",
        "with open(DATA_PATH+\"PaucBas.pickle\", \"wb\") as obj_file:\n",
        "  for site in fake_news_twitter:\n",
        "    user = TwitterUser(sname= fake_news_twitter[site])\n",
        "    user.get_all_data()\n",
        "    pickle.dump([user], obj_file, -1)\n",
        "    # print(fake_news_twitter[site])"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "get_tweets for france_soir: 3210it [00:07, 430.60it/s]\n",
            "get_tweets for ThierryRegenere:  12%|█▎        | 375/3000 [00:00<00:05, 458.22it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TweepError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTweepError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-133-be9da1eb835a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"PaucBas.pickle\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mobj_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0msite\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfake_news_twitter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0muser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTwitterUser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msname\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mfake_news_twitter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msite\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0muser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-92-25fae464f25a>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sname, _json)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msname\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_screen_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_json\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_json\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-92-25fae464f25a>\u001b[0m in \u001b[0;36mget_info\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_user_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreen_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_screen_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_all_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tweepy/binder.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    251\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tweepy/binder.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    232\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mRateLimitError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mTweepError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapi_error_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0;31m# Parse the response payload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTweepError\u001b[0m: [{'code': 63, 'message': 'User has been suspended.'}]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hC09RVl4pjHf"
      },
      "source": [
        "import pickle\n",
        "\n",
        "with open(DATA_PATH+\"PaucBas.pickle\", \"wb\") as obj_file:\n",
        "    pickle.dump([test], obj_file, -1)"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jo1XqxdVpjHg"
      },
      "source": [
        "import pickle\n",
        "\n",
        "with open(DATA_PATH+\"PaucBas.pickle\", \"rb\") as obj_file:\n",
        "    test = pickle.load(obj_file)"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeq7kaGBAJLc",
        "outputId": "4aa75bea-ebba-49bd-a7f9-122b476caf75"
      },
      "source": [
        "status_list = test[0].tweet\n",
        "\n",
        "# test4 = json.dumps(test3[0]._json)\n",
        "\n",
        "# type(test4)\n",
        "\n",
        "test2 = [status._json['text'] for status in status_list]\n",
        "len(test2)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3200"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKozVStu5MRm",
        "outputId": "faec504c-6197-4aa4-8b61-2197212230f3"
      },
      "source": [
        "objects = []\n",
        "with (open(DATA_PATH+\"PaucBas.pickle\", \"rb\")) as openfile:\n",
        "    while True:\n",
        "        try:\n",
        "            objects.append(pickle.load(openfile))\n",
        "        except EOFError:\n",
        "            break\n",
        "\n",
        "objects"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[<__main__.TwitterUser at 0x7f8285daed50>]]"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOYCILG9pjHg"
      },
      "source": [
        "import json\n",
        "\n",
        "with open(DATA_PATH+\"links.json\", \"w\") as file: \n",
        "    file.write(json.dumps(fake_news_twitter))"
      ],
      "execution_count": 99,
      "outputs": []
    }
  ]
}